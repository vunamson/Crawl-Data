from datetime import datetime
import random
from sys import _xoptions
from bs4 import BeautifulSoup
import undetected_chromedriver as uc
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time

# 1ï¸âƒ£ Cáº¥u hÃ¬nh Selenium (tÄƒng tá»‘c trÃ¬nh duyá»‡t)
# chrome_options = Options()
# chrome_options.add_argument("--headless")  # Cháº¡y khÃ´ng hiá»ƒn thá»‹ trÃ¬nh duyá»‡t
# chrome_options.add_argument("--disable-gpu")  # Táº¯t GPU tÄƒng hiá»‡u suáº¥t
# chrome_options.add_argument("--no-sandbox")  # Bá» háº¡n cháº¿ sandbox
# chrome_options.add_argument("--disable-dev-shm-usage")  # Há»— trá»£ cháº¡y trÃªn server
# chrome_options.add_argument("--disable-blink-features=AutomationControlled")  # Giáº£m kháº£ nÄƒng bá»‹ phÃ¡t hiá»‡n bot
# chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36")

# ğŸ“Œ Äá»c danh sÃ¡ch proxy tá»« file IpUs.txt
# def load_proxies(file_path="IpUs.txt"):
#     with open(file_path, "r") as file:
#         proxies = [line.strip() for line in file.readlines() if line.strip()]
#     return proxies

# ğŸ› ï¸ Kiá»ƒm tra proxy cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng
# def is_proxy_working(proxy):
#     test_url = "https://api64.ipify.org?format=json"  # API kiá»ƒm tra IP
#     proxies = {
#         "http": f"http://{proxy}",
#         "https": f"http://{proxy}",
#     }
#     try:
#         response = requests.get(test_url, proxies=proxies, timeout=5)
#         if response.status_code == 200:
#             print(f"âœ… Proxy hoáº¡t Ä‘á»™ng: {proxy}")
#             return True
#     except requests.RequestException:
#         pass
#     print(f"âŒ Proxy khÃ´ng hoáº¡t Ä‘á»™ng: {proxy}")
#     return False

# def get_random_proxy(proxies):
#     random.shuffle(proxies)  # XÃ¡o trá»™n danh sÃ¡ch proxy
#     for proxy in proxies:
#         if is_proxy_working(proxy):
#             return proxy
#     return None


def get_random_user_agent():    
    chrome_version = f"{random.randint(2, 200)}.0.0.0"  # Táº¡o sá»‘ ngáº«u nhiÃªn tá»« 2.0.0.0 - 200.0.0.0
    return f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_version} Safari/537.36"

# proxies = load_proxies()

# ğŸ› ï¸ HÃ m táº¡o WebDriver vá»›i User-Agent má»›i
def create_driver(): 
    chrome_options = uc.ChromeOptions()
    # chrome_options.add_argument("--headless")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.set_capability('LT:Options', _xoptions)

    # if proxy:
    #     chrome_options.add_argument(f"--proxy-server={proxy}")
    #     print(f"ğŸ”„ Äang sá»­ dá»¥ng Proxy: {proxy}")
    # ğŸ”„ ThÃªm User-Agent ngáº«u nhiÃªn
    user_agent = get_random_user_agent()
    chrome_options.add_argument(f"user-agent={user_agent}")
    
    print(f"ğŸ†• ÄÃ£ thay Ä‘á»•i User-Agent: {user_agent}")
    # return uc.Chrome(headless=False)
    return uc.Chrome(headless=False)
# Khá»Ÿi táº¡o WebDriver duy nháº¥t (trÃ¡nh táº¡o láº¡i má»—i láº§n láº·p)
# current_proxy = get_random_proxy(proxies)
def check_publish_date(driver, url):
    try:
        # driver.get(url)
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(3)
        page_source = driver.page_source
        # source = driver.execute_cdp_cmd("Page.getResourceContent", {"frameId": "1", "url": url})
        webGoLiveDate = None
        # print('webGoLiveDate',webGoLiveDate)
        str_page_source = str(page_source)
        print('len' , len(str_page_source))
        indices = [i for i in range(len(str_page_source)) if str_page_source.startswith("webGoLiveDate", i)]
        for idx in indices:
            start_idx = idx + len("webGoLiveDate") +2  # Äáº§u tiÃªn sau "webGoLiveDate"
            end_idx = start_idx + 10  # Láº¥y 10 kÃ½ tá»± sau Ä‘Ã³
            snippet = page_source[start_idx:end_idx]
            print('snippet' , snippet )
            if snippet.isdigit():                                                
                webGoLiveDate = int(snippet)
            else : 'khong phai so nguyen'
        print('webGoLiveDate' ,webGoLiveDate)
        if webGoLiveDate:
            # start_idx = webGoLiveDate + len(webGoLiveDate) + 2
            # end_idx = page_source.find(',', start_idx)
            # timestamp_str = page_source[start_idx:end_idx].strip()
            
            # Chuyá»ƒn Unix timestamp sang datetime
            publish_date = datetime.fromtimestamp(int(webGoLiveDate))
            print('publish_date',publish_date)
            start_date = datetime(2025, 3, 1, 0, 0, 0)
            end_date = datetime(2025, 4, 9, 0, 0, 0)
            print('start_date' ,start_date <= publish_date < end_date )
            if start_date <= publish_date < end_date :
                return publish_date
            else: return None
    except Exception as e:
        print(f"Lá»—i kiá»ƒm tra ngÃ y Ä‘Äƒng: {e}")
    return None 

def check_publish_date_false(driver, url):
    try:
        # driver.get(url)
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(3)
        page_source = driver.page_source
        # source = driver.execute_cdp_cmd("Page.getResourceContent", {"frameId": "1", "url": url})
        webGoLiveDate = None
        # print('webGoLiveDate',webGoLiveDate)
        str_page_source = str(page_source)
        print('len' , len(str_page_source))
        indices = [i for i in range(len(str_page_source)) if str_page_source.startswith("webGoLiveDate", i)]
        for idx in indices:
            start_idx = idx + len("webGoLiveDate") +2  # Äáº§u tiÃªn sau "webGoLiveDate"
            end_idx = start_idx + 10  # Láº¥y 10 kÃ½ tá»± sau Ä‘Ã³
            snippet = page_source[start_idx:end_idx]
            print('snippet' , snippet )
            if snippet.isdigit():                                                
                webGoLiveDate = int(snippet)
            else : 'khong phai so nguyen'
        print('webGoLiveDate' ,webGoLiveDate)
        if webGoLiveDate:
            # start_idx = webGoLiveDate + len(webGoLiveDate) + 2
            # end_idx = page_source.find(',', start_idx)
            # timestamp_str = page_source[start_idx:end_idx].strip()
            
            # Chuyá»ƒn Unix timestamp sang datetime
            publish_date = datetime.fromtimestamp(int(webGoLiveDate))
            start_date = datetime(2025, 3, 1, 0, 0, 0)
            end_date = datetime(2025, 4, 9, 0, 0, 0)
            print('start_date' ,start_date <= publish_date < end_date )
            return start_date > publish_date 
    except Exception as e:
        print(f"Lá»—i kiá»ƒm tra ngÃ y Ä‘Äƒng: {e}")
    return False 


driver = create_driver()
product_links = []
url = "https://www.shopncaasports.com/jerseys/d-31774590+z-9774861-1004768413?sortOption=NewestArrivals"
driver.get(url)
time.sleep(5)
count = 0

while True:
    try:
        if(count == 32) : break
        count = count + 1
        # Äá»£i trang táº£i hoÃ n táº¥t trÆ°á»›c khi láº¥y dá»¯ liá»‡u
        WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.TAG_NAME, 'body'))
        )
        # Láº¥y táº¥t cáº£ áº£nh sáº£n pháº©m trÃªn trang hiá»‡n táº¡i
        links = driver.find_elements(By.CSS_SELECTOR, "a.color-black")
        print('links', len(links)) 
        # LÆ°u danh sÃ¡ch cÃ¡c link sáº£n pháº©m
        for link in links:
            href = link.get_attribute("href")
            if href and href not in product_links:
                # if check_publish_date(browser, href):
                product_links.append(href)

        # Kiá»ƒm tra xem cÃ³ nÃºt next page hay khÃ´ng
        try:
            next_button = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "a[data-trk-id='next-page']"))
            )
            aria_disabled = next_button.get_attribute("aria-disabled")

            if aria_disabled == "true":
                break  # KhÃ´ng cÃ²n trang tiáº¿p theo

            next_button.click()

            # Äá»£i trang má»›i táº£i hoÃ n táº¥t
            # WebDriverWait(browser, 10).until(
            #     EC.staleness_of(images[0])  # Chá» cho trang cÅ© biáº¿n máº¥t
            # )
        except (NoSuchElementException, TimeoutException):
            break

    except TimeoutException:
        print("KhÃ´ng tÃ¬m tháº¥y pháº§n tá»­ mong muá»‘n, thoÃ¡t chÆ°Æ¡ng trÃ¬nh.")
        break


# 3ï¸âƒ£ Crawl dá»¯ liá»‡u tá»«ng sáº£n pháº©m
data = []
for index, link in enumerate(product_links):
    try:
        # print('index' , index)
        # if index > 0 and index  == 1 : 
            # driver.quit()
            # driver = create_driver()
            # driver.delete_all_cookies()
            # print('if')
            # current_proxy = get_random_proxy(proxies)
            # driver = create_driver(current_proxy)
        # else : print('else')
        driver.get(link)
        # driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        if check_publish_date_false(driver,link) : break
        date = check_publish_date(driver,link)
        if date :

        # if index == 0 : check_publish_date(driver,link)
        # else: break
            print(f"ğŸ” Äang láº¥y dá»¯ liá»‡u tá»«: {link} ({index + 1}/{len(product_links)})")
            # Sá»­ dá»¥ng WebDriverWait thay vÃ¬ time.sleep()
            WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'h1[data-talos="labelPdpProductTitle"]'))
            )

            # Láº¥y tÃªn sáº£n pháº©m

            # TÃ¬m danh sÃ¡ch mÃ u sáº¯c (náº¿u cÃ³)
            color_buttons = driver.find_elements(By.CSS_SELECTOR, 'a[data-trk-id="color-selector"]')

            if color_buttons:
                for button in color_buttons:
                    
                    try:
                        driver.execute_script("arguments[0].click();", button)
                        time.sleep(1)  # Giáº£m thá»i gian sleep
                        name_element = driver.find_element(By.CSS_SELECTOR, 'h1[data-talos="labelPdpProductTitle"]')
                        name = name_element.text.strip() if name_element else "N/A"
                        # Láº¥y danh sÃ¡ch áº£nh sau khi chá»n mÃ u
                        img_elements1 = driver.find_elements(By.CSS_SELECTOR, 'img.thumbnail-image')
                        img_elements2 = driver.find_elements(By.XPATH, '//img[@loading="lazy" and @alt=""]')
                        img_elements = img_elements1 if len(img_elements1) > 0 else img_elements2
                        img_links = [img.get_attribute("src") for img in img_elements]

                        # LÆ°u dá»¯ liá»‡u
                        img_links_str = ", ".join(img_links) if img_links else "Lá»–I"
                        data.append([name, img_links_str,date])
                        print(f"âœ… {name} ({len(img_links)} áº£nh)")
                    except Exception as e:
                        print(f"âš ï¸ Lá»—i khi click mÃ u: {e}")
                        data.append([name, "Lá»–I"])
            else:
                name_element = driver.find_element(By.CSS_SELECTOR, 'h1[data-talos="labelPdpProductTitle"]')
                name = name_element.text.strip() if name_element else "N/A"
                img_elements1 = driver.find_elements(By.CSS_SELECTOR, 'img.thumbnail-image')
                img_elements2 = driver.find_elements(By.XPATH, '//img[@loading="lazy" and @alt=""]')
                img_elements = img_elements1 if len(img_elements1) > 0 else img_elements2
                img_links = [img.get_attribute("src") for img in img_elements]

                img_links_str = ", ".join(img_links) if img_links else "Lá»–I"
                data.append([name, img_links_str,date])
                print(f"âœ… {name} ({len(img_links)} áº£nh)")

    except Exception as e:
        print(f"âŒ Lá»—i khi crawl {link}: {e}")
        driver.quit()
        time.sleep(10)
        driver = create_driver()
        data.append(["Lá»–I", "Lá»–I"])

# 4ï¸âƒ£ LÆ°u dá»¯ liá»‡u vÃ o file Excel
driver.quit()
del driver
df = pd.DataFrame(data, columns=["Name", "Image Links","Date"])
df.to_excel("output_ports_shop_1-3--9-4.xlsx", index=False, engine="openpyxl")

print("ğŸ‰ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o output1.xlsx!")